// Copyright (c) 2015 Intel Corporation. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

#include "realsense/face_tracking/win/face_tracking_object.h"

// This file is auto-generated by face_tracking.idl
#include "face_tracking.h" // NOLINT

#include "base/bind.h"
#include "base/logging.h"
#include "third_party/libpxc/include/pxcfaceconfiguration.h"

namespace {

using NativeModeType = PXCFaceConfiguration::TrackingModeType;
using NativeStrategyType = PXCFaceConfiguration::TrackingStrategyType;
using JSModeType = realsense::jsapi::face_tracking::TrackingModeType;
using JSStrategyType = realsense::jsapi::face_tracking::TrackingStrategyType;
using JSFaceConfigurationData =
    realsense::jsapi::face_tracking::FaceConfigurationData;
using JSDetectionConfiguration =
    realsense::jsapi::face_tracking::DetectionConfiguration;
using JSLandmarksConfiguration =
    realsense::jsapi::face_tracking::LandmarksConfiguration;

NativeModeType TrackingModeJS2Native(JSModeType params_mode) {
  NativeModeType mode;
  if (params_mode == JSModeType::TRACKING_MODE_TYPE_COLOR) {
    mode = NativeModeType::FACE_MODE_COLOR;
  } else if (params_mode == JSModeType::TRACKING_MODE_TYPE_COLOR_DEPTH) {
    mode = NativeModeType::FACE_MODE_COLOR_PLUS_DEPTH;
  } else {
    mode = NativeModeType::FACE_MODE_COLOR_PLUS_DEPTH;
  }

  return mode;
}

NativeStrategyType TrackingStrategyJS2Native(JSStrategyType params_strategy) {
  NativeStrategyType strategy;
  switch (params_strategy) {
    case JSStrategyType::TRACKING_STRATEGY_TYPE_APPEARANCE_TIME:
      strategy = NativeStrategyType::STRATEGY_APPEARANCE_TIME;
      break;
    case JSStrategyType::TRACKING_STRATEGY_TYPE_CLOSEST_FARTHEST:
      strategy = NativeStrategyType::STRATEGY_CLOSEST_TO_FARTHEST;
      break;
    case JSStrategyType::TRACKING_STRATEGY_TYPE_FARTHEST_CLOSEST:
      strategy = NativeStrategyType::STRATEGY_FARTHEST_TO_CLOSEST;
      break;
    case JSStrategyType::TRACKING_STRATEGY_TYPE_LEFT_RIGHT:
      strategy = NativeStrategyType::STRATEGY_LEFT_TO_RIGHT;
      break;
    case JSStrategyType::TRACKING_STRATEGY_TYPE_RIGHT_LEFT:
      strategy = NativeStrategyType::STRATEGY_RIGHT_TO_LEFT;
      break;
    default:
      strategy = NativeStrategyType::STRATEGY_APPEARANCE_TIME;
      break;
  }

  return strategy;
}

JSModeType TrackingModeNative2JS(NativeModeType mode) {
  JSModeType mode_js = JSModeType::TRACKING_MODE_TYPE_NONE;

  if (mode == NativeModeType::FACE_MODE_COLOR) {
    mode_js = JSModeType::TRACKING_MODE_TYPE_COLOR;
  } else if (mode == NativeModeType::FACE_MODE_COLOR_PLUS_DEPTH) {
    mode_js = JSModeType::TRACKING_MODE_TYPE_COLOR_DEPTH;
  }

  return mode_js;
}

JSStrategyType TrackingStrategyNative2JS(NativeStrategyType strategy) {
  JSStrategyType strategy_js = JSStrategyType::TRACKING_STRATEGY_TYPE_NONE;

  switch (strategy) {
    case NativeStrategyType::STRATEGY_APPEARANCE_TIME:
      strategy_js = JSStrategyType::TRACKING_STRATEGY_TYPE_APPEARANCE_TIME;
      break;
    case NativeStrategyType::STRATEGY_CLOSEST_TO_FARTHEST:
      strategy_js = JSStrategyType::TRACKING_STRATEGY_TYPE_CLOSEST_FARTHEST;
      break;
    case NativeStrategyType::STRATEGY_FARTHEST_TO_CLOSEST:
      strategy_js = JSStrategyType::TRACKING_STRATEGY_TYPE_FARTHEST_CLOSEST;
      break;
    case NativeStrategyType::STRATEGY_LEFT_TO_RIGHT:
      strategy_js = JSStrategyType::TRACKING_STRATEGY_TYPE_LEFT_RIGHT;
      break;
    case NativeStrategyType::STRATEGY_RIGHT_TO_LEFT:
      strategy_js = JSStrategyType::TRACKING_STRATEGY_TYPE_RIGHT_LEFT;
      break;
    default:
      strategy_js = JSStrategyType::TRACKING_STRATEGY_TYPE_NONE;
      break;
  }

  return strategy_js;
}

pxcStatus ApplyChangesConfig(
    PXCFaceConfiguration* config, const JSFaceConfigurationData& config_data) {
  if (config_data.mode != JSModeType::TRACKING_MODE_TYPE_NONE) {
    PXCFaceConfiguration::TrackingModeType mode =
        TrackingModeJS2Native(config_data.mode);
    config->SetTrackingMode(mode);
    DLOG(INFO) << "ApplyChangesConfig: TrackingMode is " << mode;
  }

  if (config_data.strategy != JSStrategyType::TRACKING_STRATEGY_TYPE_NONE) {
    PXCFaceConfiguration::TrackingStrategyType strategy =
        TrackingStrategyJS2Native(config_data.strategy);
    config->strategy = strategy;
    DLOG(INFO) << "ApplyChangesConfig: TrackingStrategy is " << strategy;
  }

  if (config_data.detection) {
    JSDetectionConfiguration* detection = config_data.detection.get();
    if (detection->enable) {
      DLOG(INFO) << "ApplyChangesConfig: Enable detection "
          << *(detection->enable.get());
      config->detection.isEnabled = *(detection->enable.get());
    }
    if (detection->max_faces) {
      DLOG(INFO) << "ApplyChangesConfig: Set detection max faces: "
          << *(detection->max_faces.get());
      config->detection.maxTrackedFaces = *(detection->max_faces.get());
    }
  }
  if (config_data.landmarks) {
    JSLandmarksConfiguration* landmarks = config_data.landmarks.get();
    if (landmarks->enable) {
      DLOG(INFO) << "ApplyChangesConfig: Enable landmarks "
          << *(landmarks->enable.get());
      config->landmarks.isEnabled = *(landmarks->enable.get());
    }
    if (landmarks->max_faces) {
      DLOG(INFO) << "ApplyChangesConfig: Set landmarks max faces: "
          << *(landmarks->max_faces.get());
      config->landmarks.maxTrackedFaces = *(landmarks->max_faces.get());
    }
    // landmarks->num_landmarks setting would take no effect,
    // this field is just for readonly and can not be configured.
  }

  return config->ApplyChanges();
}

void RetrieveConfig(
    PXCFaceConfiguration* config, JSFaceConfigurationData* out_data) {
  // Fill JS FaceConfiguration structure out_data.
  out_data->mode = TrackingModeNative2JS(config->GetTrackingMode());
  out_data->strategy = TrackingStrategyNative2JS(config->strategy);

  // DetectionConfiguration.
  out_data->detection.reset(new JSDetectionConfiguration());
  JSDetectionConfiguration* detection = out_data->detection.get();
  detection->enable.reset(new bool(config->detection.isEnabled != 0));
  detection->max_faces.reset(new int(config->detection.maxTrackedFaces));

  // LandmarksConfiguration.
  out_data->landmarks.reset(new JSLandmarksConfiguration());
  JSLandmarksConfiguration* landmarks = out_data->landmarks.get();
  landmarks->enable.reset(new bool(config->landmarks.isEnabled != 0));
  landmarks->max_faces.reset(new int(config->landmarks.maxTrackedFaces));
  landmarks->num_landmarks.reset(new int(config->landmarks.numLandmarks));
}

}  // namespace

namespace realsense {
namespace face_tracking {

using namespace realsense::jsapi::face_tracking; // NOLINT
using namespace xwalk::common; // NOLINT

FaceTrackingObject::FaceTrackingObject()
    : state_(NOT_READY),
      on_processedsample_(false),
      on_error_(false),
      face_tracking_thread_("FaceTrackingPreviewThread"),
      message_loop_(base::MessageLoopProxy::current()),
      session_(NULL),
      sense_manager_(NULL),
      face_output_(NULL),
      face_config_(NULL),
      latest_color_image_(NULL),
      latest_depth_image_(NULL),
      binary_message_size_(0) {
  handler_.Register("start",
                    base::Bind(&FaceTrackingObject::OnStart,
                               base::Unretained(this)));
  handler_.Register("stop",
                    base::Bind(&FaceTrackingObject::OnStop,
                               base::Unretained(this)));
  handler_.Register("getProcessedSample",
                    base::Bind(&FaceTrackingObject::OnGetProcessedSample,
                               base::Unretained(this)));
  handler_.Register("set",
                    base::Bind(&FaceTrackingObject::OnSetConf,
                               base::Unretained(this)));
  handler_.Register("getDefaults",
                    base::Bind(&FaceTrackingObject::OnGetDefaultsConf,
                               base::Unretained(this)));
  handler_.Register("get",
                    base::Bind(&FaceTrackingObject::OnGetConf,
                               base::Unretained(this)));
}

FaceTrackingObject::~FaceTrackingObject() {
  OnStop(NULL);
  Destroy();
}


void FaceTrackingObject::StartEvent(const std::string& type) {
  if (type == std::string("processedsample")) {
    on_processedsample_ = true;
  } else if (type == std::string("error")) {
    on_error_ = true;
  }
}

void FaceTrackingObject::StopEvent(const std::string& type) {
  if (type == std::string("processedsample")) {
    on_processedsample_ = false;
  } else if (type == std::string("error")) {
    on_error_ = false;
  }
}

void FaceTrackingObject::OnStart(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  if (face_tracking_thread_.IsRunning()) {
    info->PostResult(
        Start::Results::Create(
            std::string(), std::string("Face tracking is already started")));
    return;  // Wrong state.
  }

  if (!Init()) {
    info->PostResult(
        Start::Results::Create(
            std::string(), std::string("Can't prepare pipeline")));
    return;
  }

  face_tracking_thread_.Start();

  face_tracking_thread_.message_loop()->PostTask(
      FROM_HERE,
      base::Bind(&FaceTrackingObject::OnStartPipeline,
                 base::Unretained(this),
                 base::Passed(&info)));
}

void FaceTrackingObject::OnStop(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  if (!face_tracking_thread_.IsRunning()) {
    if (info.get()) {
      info->PostResult(
          Stop::Results::Create(
              std::string(),
              std::string("Face tracking is not started yet")));
    }
    return;  // Wrong state.
  }

  face_tracking_thread_.message_loop()->PostTask(
      FROM_HERE,
      base::Bind(&FaceTrackingObject::OnStopPipeline,
                 base::Unretained(this),
                 base::Passed(&info)));

  face_tracking_thread_.Stop();
}

void FaceTrackingObject::OnGetProcessedSample(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  if (!face_tracking_thread_.IsRunning()) {
    ProcessedSample processed_sample;
    GetProcessedSample::Results::Create(
        processed_sample, std::string("Pipeline is not started"));
    return;
  }

  face_tracking_thread_.message_loop()->PostTask(
      FROM_HERE,
      base::Bind(&FaceTrackingObject::OnGetProcessedSampleOnPipeline,
                 base::Unretained(this),
                 base::Passed(&info)));
}

void FaceTrackingObject::OnSetConf(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  // Pipeline is not running, do it on current thread.
  if (!face_tracking_thread_.IsRunning()) {
    if (!Init()) {
      info->PostResult(
          Set::Results::Create(
              std::string(), std::string("Can't prepare pipeline")));
      return;
    }

    DoSetConf(info.Pass());
  } else {
    // Pipeline is running, do it on tracking thread.
    face_tracking_thread_.message_loop()->PostTask(
        FROM_HERE,
        base::Bind(&FaceTrackingObject::DoSetConf,
                   base::Unretained(this),
                   base::Passed(&info)));
  }
}

void FaceTrackingObject::OnGetDefaultsConf(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  // Pipeline is not running, do it on current thread.
  if (!face_tracking_thread_.IsRunning()) {
    if (!Init()) {
      JSFaceConfigurationData config_data;
      info->PostResult(
          GetDefaults::Results::Create(
              config_data, std::string("Can't prepare pipeline")));
      return;
    }

    DoGetDefaultsConf(info.Pass());
  } else {
    // Pipeline is running, do it on tracking thread.
    face_tracking_thread_.message_loop()->PostTask(
        FROM_HERE,
        base::Bind(&FaceTrackingObject::DoGetDefaultsConf,
                   base::Unretained(this),
                   base::Passed(&info)));
  }
}

void FaceTrackingObject::OnGetConf(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  // Pipeline is not running, do it on current thread.
  if (!face_tracking_thread_.IsRunning()) {
    if (!Init()) {
      JSFaceConfigurationData config_data;
      info->PostResult(
          Get::Results::Create(
              config_data, std::string("Can't prepare pipeline")));
      return;
    }

    DoGetConf(info.Pass());
  } else {
    // Pipeline is running, do it on tracking thread.
    face_tracking_thread_.message_loop()->PostTask(
        FROM_HERE,
        base::Bind(&FaceTrackingObject::DoGetConf,
                   base::Unretained(this),
                   base::Passed(&info)));
  }
}

void FaceTrackingObject::OnStartPipeline(
  scoped_ptr<XWalkExtensionFunctionInfo> info) {
  DCHECK_EQ(face_tracking_thread_.message_loop(), base::MessageLoop::current());
  DCHECK(state_ == IDLE);

  // Init sense manager.
  pxcStatus status = sense_manager_->Init();
  if (status < PXC_STATUS_NO_ERROR) {
    DLOG(ERROR) << "Failed to init sense manager: " << status;
    info->PostResult(
        Start::Results::Create(
            std::string(), "Failed to init sense manager"));
    ReleasePipelineResources();
    StopFaceTrackingThread();
    return;
  }

  if (face_config_->GetTrackingMode() ==
      PXCFaceConfiguration::TrackingModeType::FACE_MODE_COLOR_PLUS_DEPTH) {
    DLOG(INFO) << "Face color_depth tracking mode, set for DS4 device";
    // Quote from C++ SDK FaceTracking sample application.
    PXCCapture::DeviceInfo device_info;
    sense_manager_->QueryCaptureManager()->QueryDevice()
        ->QueryDeviceInfo(&device_info);

    if (device_info.model == PXCCapture::DEVICE_MODEL_DS4) {
      sense_manager_->QueryCaptureManager()->QueryDevice()
          ->SetDSLeftRightExposure(26);
      sense_manager_->QueryCaptureManager()->QueryDevice()
          ->SetDepthConfidenceThreshold(0);
    }
  }

  // Create face module output.
  face_output_ = sense_manager_->QueryFace()->CreateOutput();
  if (!face_output_) {
    DLOG(ERROR) << "Failed to create face output";
    info->PostResult(
        Start::Results::Create(
            std::string(), "Failed to create face output"));
    ReleasePipelineResources();
    StopFaceTrackingThread();
    return;
  }

  // As we called EnableFace(),
  // SDK will enable the corresponding streams implicitly.
  // We create color/depth images according current stream profiles.
  if (!CreateProcessedSampleImages()) {
    info->PostResult(
        Start::Results::Create(
            std::string(), "Failed to create processed sample images"));
    ReleasePipelineResources();
    StopFaceTrackingThread();
    return;
  }

  DLOG(INFO) << "Start, State transit from IDLE to TRACKING";
  state_ = TRACKING;

  face_tracking_thread_.message_loop()->PostTask(
      FROM_HERE,
      base::Bind(&FaceTrackingObject::OnRunPipeline,
                 base::Unretained(this)));

  info->PostResult(
      Start::Results::Create(
          std::string("success"), std::string()));
}

void FaceTrackingObject::OnRunPipeline() {
  DCHECK_EQ(face_tracking_thread_.message_loop(), base::MessageLoop::current());
  if (state_ != TRACKING) return;

  pxcStatus status = sense_manager_->AcquireFrame(true);
  if (status < PXC_STATUS_NO_ERROR) {
    DLOG(ERROR) << "AcquiredFrame failed: " << status;
    if (on_error_) {
      ErrorEvent event;
      event.status = "Fail to AcquireFrame. Stop.";
      scoped_ptr<base::ListValue> eventData(new base::ListValue);
      eventData->Append(event.ToValue().release());
      DispatchEvent("error", eventData.Pass());
    }

    ReleasePipelineResources();
    StopFaceTrackingThread();
    return;
  }

  face_output_->Update();
  PXCCapture::Sample* face_sample = sense_manager_->QueryFaceSample();
  if (face_sample) {
    // At least we should have color image!
    if (!face_sample->color) {
      if (on_error_) {
        ErrorEvent event;
        event.status = "Fail to query face sample";
        scoped_ptr<base::ListValue> eventData(new base::ListValue);
        eventData->Append(event.ToValue().release());
        DispatchEvent("error", eventData.Pass());
      }

      ReleasePipelineResources();
      StopFaceTrackingThread();
      return;
    }

    if (on_processedsample_) {
      latest_color_image_->CopyImage(face_sample->color);
      if (latest_depth_image_ && face_sample->depth) {
        latest_depth_image_->CopyImage(face_sample->depth);
      }
      DispatchEvent("processedsample");
    }
  } else {
    // face_sample is NULL means face module is paused
    // or error happened. Just ignore and continue next frame.
    DLOG(ERROR) << "QueryFaceSample() returned NULL";
  }

  sense_manager_->ReleaseFrame();

  face_tracking_thread_.message_loop()->PostTask(
      FROM_HERE,
      base::Bind(&FaceTrackingObject::OnRunPipeline,
                 base::Unretained(this)));
}

void FaceTrackingObject::OnStopPipeline(
    scoped_ptr<xwalk::common::XWalkExtensionFunctionInfo> info) {
  DCHECK_EQ(face_tracking_thread_.message_loop(), base::MessageLoop::current());

  ReleasePipelineResources();

  if (info.get()) {
    info->PostResult(
        Stop::Results::Create(
            std::string("Success"), std::string()));
  }
}

void FaceTrackingObject::OnGetProcessedSampleOnPipeline(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  DCHECK_EQ(face_tracking_thread_.message_loop(), base::MessageLoop::current());

  bool fail = false;

  if (state_ != TRACKING) {
    ProcessedSample processed_sample;
    info->PostResult(
        GetProcessedSample::Results::Create(
            processed_sample,
            std::string("Is not tracking, no processed_sample")));
    return;
  }

  PXCImage* color = latest_color_image_;
  PXCImage* depth = latest_depth_image_;

  const size_t post_data_size = CalculateBinaryMessageSize();
  if (binary_message_size_ < post_data_size) {
    binary_message_.reset(new uint8[post_data_size]);
    binary_message_size_ = post_data_size;
  }

  size_t offset = 0;
  int* int_array = reinterpret_cast<int*>(binary_message_.get());
  // Fill ProcessedSample::color image.
  PXCImage::ImageInfo color_info = color->QueryInfo();
  int_array[1] = 1;  // 1 for PixelFormat::PIXEL_FORMAT_RGB32
  int_array[2] = color_info.width;
  int_array[3] = color_info.height;
  offset += 4 * sizeof(int);
  PXCImage::ImageData color_data;
  pxcStatus status = color->AcquireAccess(
      PXCImage::ACCESS_READ, PXCImage::PIXEL_FORMAT_RGB32, &color_data);
  uint8_t* uint8_array =
      reinterpret_cast<uint8_t*>(binary_message_.get() + offset);
  if (status >= PXC_STATUS_NO_ERROR) {
    int k = 0;
    uint8_t* rgb32 = reinterpret_cast<uint8_t*>(color_data.planes[0]);
    for (int y = 0; y < color_info.height; ++y) {
      for (int x = 0; x < color_info.width; ++x) {
        int i = (x + color_info.width * y) * 4;
        uint8_array[k++] = rgb32[i + 2];
        uint8_array[k++] = rgb32[i + 1];
        uint8_array[k++] = rgb32[i];
        uint8_array[k++] = rgb32[i + 3];
      }
    }
    offset += color_info.width * color_info.height * 4;
    color->ReleaseAccess(&color_data);
  } else {
    fail = true;
    DLOG(INFO) << "Failed to access color image data: " << status;
  }

  int_array = reinterpret_cast<int*>(binary_message_.get() + offset);
  // Fill ProcessedSample::depth image.
  if (!fail) {
    if (depth) {
      PXCImage::ImageInfo depth_info = depth->QueryInfo();
      int_array[0] = 2;  // 2 for PixelFormat::PIXEL_FORMAT_DEPTH
      int_array[1] = depth_info.width;
      int_array[2] = depth_info.height;
      offset += 3 * sizeof(int);
      PXCImage::ImageData depth_data;
      status = depth->AcquireAccess(
          PXCImage::ACCESS_READ, PXCImage::PIXEL_FORMAT_DEPTH, &depth_data);
      uint16_t* uint16_array = reinterpret_cast<uint16_t*>(
          binary_message_.get() + offset);
      if (status >= PXC_STATUS_NO_ERROR) {
        int k = 0;
        for (int y = 0; y < depth_info.height; ++y) {
          for (int x = 0; x < depth_info.width; ++x) {
            uint16_t* depth16 =
                reinterpret_cast<uint16_t*>(
                    depth_data.planes[0] + depth_data.pitches[0] * y);
            uint16_array[k++] = depth16[x];
          }
        }
        offset += depth_info.width * depth_info.height * 2;
        depth->ReleaseAccess(&depth_data);
      } else {
        fail = true;
        DLOG(INFO) << "Failed to access depth image data: " << status;
      }
    } else {
      // If no depth stream, only set depth width and height as 0.
      int_array[0] = 2;
      int_array[1] = 0;
      int_array[2] = 0;
      offset += 3 * sizeof(int);
    }
  }

  // Fill ProcessedSample::faces data.
  if (!fail) {
    const int num_of_faces = face_output_->QueryNumberOfDetectedFaces();
    bool detection_enabled = face_config_->detection.isEnabled != 0;
    bool landmarks_enabled = face_config_->landmarks.isEnabled != 0;

    int_array = reinterpret_cast<int*>(binary_message_.get() + offset);
    int_array[0] = num_of_faces;
    int_array[1] = detection_enabled ? 1 : 0;
    int_array[2] = landmarks_enabled ? 1 : 0;
    offset += 3 * sizeof(int);

    for (int i = 0; i < num_of_faces; i++) {
      PXCFaceData::Face* trackedFace = face_output_->QueryFaceByIndex(i);

      // Fill FaceData::faceId
      *(reinterpret_cast<int*>(binary_message_.get() + offset)) =
          trackedFace->QueryUserID();
      offset += sizeof(int);

      if (detection_enabled) {
        const PXCFaceData::DetectionData* detectionData =
            trackedFace->QueryDetection();
        // Fill FaceData::detection data.
        if (detectionData) {
          int_array = reinterpret_cast<int*>(binary_message_.get() + offset);
          PXCRectI32 rectangle;
          if (detectionData->QueryBoundingRect(&rectangle)) {
            DLOG(INFO) << "Traced face No." << i << ": "
                << rectangle.x << ", " << rectangle.y << ", "
                << rectangle.w << ", " << rectangle.h;
            int_array[0] = rectangle.x;
            int_array[1] = rectangle.y;
            int_array[2] = rectangle.w;
            int_array[3] = rectangle.h;
          }
          offset += 4 * sizeof(int);

          pxcF32 avgDepth;
          if (detectionData->QueryFaceAverageDepth(&avgDepth)) {
            *(reinterpret_cast<float*>(binary_message_.get() + offset)) =
                avgDepth;
          }
          offset += sizeof(float);
        } else {
          // In case of no detection data.
          memset(binary_message_.get() + offset,
                 0,
                 4 * sizeof(int) + sizeof(float));
          offset += (4 * sizeof(int) + sizeof(float));
        }
      }

      if (landmarks_enabled) {
        const PXCFaceData::LandmarksData* landmarkData =
            trackedFace->QueryLandmarks();
        // Fill FaceData::landmarks data.
        if (landmarkData) {
          const int num_of_points = landmarkData->QueryNumPoints();
          DCHECK(num_of_points == face_config_->landmarks.numLandmarks);
          *(reinterpret_cast<int*>(binary_message_.get() + offset)) =
              num_of_points;
          offset += sizeof(int);

          PXCFaceData::LandmarkPoint landmark_point;
          for (int j = 0; j < num_of_points; j++) {
            int_array = reinterpret_cast<int*>(binary_message_.get() + offset);
            landmarkData->QueryPoint(j, &landmark_point);

            DCHECK(landmark_point.source.index == j);
            int_array[0] = landmark_point.source.alias;
            int_array[1] = landmark_point.confidenceImage;
            int_array[2] = landmark_point.confidenceWorld;
            offset += 3 * sizeof(int);

            float* float_array =
                reinterpret_cast<float*>(binary_message_.get() + offset);
            float_array[0] = landmark_point.world.x;
            float_array[1] = landmark_point.world.y;
            float_array[2] = landmark_point.world.z;
            float_array[3] = landmark_point.image.x;
            float_array[4] = landmark_point.image.y;
            offset += 5 * sizeof(float);
          }
        } else {
          // No landmark data for this face.
          *(reinterpret_cast<int*>(binary_message_.get() + offset)) = 0;
          offset += sizeof(int);
        }
      }
    }
  }

  if (fail) {
    ProcessedSample processed_sample;
    info->PostResult(
        GetProcessedSample::Results::Create(
            processed_sample,
            std::string("Failed to prepare processed_sample")));
  } else {
    DCHECK(offset <= post_data_size);
    scoped_ptr<base::ListValue> result(new base::ListValue());
    result->Append(base::BinaryValue::CreateWithCopiedBuffer(
        reinterpret_cast<const char*>(binary_message_.get()),
        offset));
    info->PostResult(result.Pass());
  }
}

// May run on face extension thread or face tracking thread.
void FaceTrackingObject::DoSetConf(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  // Pipeline is exiting because of error
  if (state_ == NOT_READY) {
    info->PostResult(
        Set::Results::Create(
            std::string(), std::string("Pipeline is not ready")));
    return;
  }

  scoped_ptr<Set::Params> params(
      Set::Params::Create(*info->arguments()));
  if (!params) {
    info->PostResult(
        Set::Results::Create(
            std::string(), std::string("Malformed parameters")));
    return;
  }

  // Apply face configurations from JS side.
  pxcStatus status = ApplyChangesConfig(face_config_, params->face_conf);
  if (status < PXC_STATUS_NO_ERROR) {
    DLOG(ERROR) << "ApplyChangesConfig() failed: " << status;
    info->PostResult(
        Set::Results::Create(
            std::string(), std::string("Failed to set face configuration")));
    return;
  }
  info->PostResult(
      Set::Results::Create(
          std::string("Success"), std::string()));
}

// May run on face extension thread or face tracking thread.
void FaceTrackingObject::DoGetDefaultsConf(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  JSFaceConfigurationData config_data;

  // Pipeline is exiting because of error
  if (state_ == NOT_READY) {
    info->PostResult(
        GetDefaults::Results::Create(
            config_data, std::string("Pipeline is not ready")));
    return;
  }

  // Call native restoreDefaults().
  face_config_->RestoreDefaults();

  // Get face configurations values.
  RetrieveConfig(face_config_, &config_data);
  // Post FaceConfigurationData to JS side.
  info->PostResult(
      GetDefaults::Results::Create(
          config_data, std::string()));
}

// May run on face extension thread or face tracking thread.
void FaceTrackingObject::DoGetConf(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  JSFaceConfigurationData config_data;

  // Pipeline is exiting because of error
  if (state_ == NOT_READY) {
    info->PostResult(
        Get::Results::Create(
            config_data, std::string("Pipeline is not ready")));
    return;
  }

  // Call native update().
  pxcStatus status = face_config_->Update();
  if (status < PXC_STATUS_NO_ERROR) {
    DLOG(ERROR) << "Face config update() failed: " << status;
    info->PostResult(
        Get::Results::Create(
            config_data, std::string("Failed to get face configuration")));
    return;
  }

  // Get face configurations values.
  RetrieveConfig(face_config_, &config_data);
  // Post FaceConfigurationData to JS side.
  info->PostResult(
      Get::Results::Create(
          config_data, std::string()));
}

bool FaceTrackingObject::Init() {
  // Assure no race condition between current thread and face_tracking_thread_
  DCHECK(!face_tracking_thread_.IsRunning());

  if (state_ != NOT_READY) {
    return true;
  }

  // Create session.
  if (!session_) {
    session_ = PXCSession::CreateInstance();
    if (!session_) {
      DLOG(ERROR) << "Failed to create session";
      return false;
    }
  }

  // Create sense manager.
  if (!sense_manager_) {
    sense_manager_ = session_->CreateSenseManager();
    if (!sense_manager_) {
      DLOG(ERROR) << "Failed to create sense manager";
      return false;
    }
  }

  // Enable face module in sense manager.
  sense_manager_->EnableFace();
  PXCFaceModule* face_module = sense_manager_->QueryFace();
  if (!face_module) {
    DLOG(ERROR) << "Failed to enable face module";
    return false;
  }

  // Create FaceConfiguration instance.
  if (face_config_) {
    face_config_->Release();
  }
  face_config_ = face_module->CreateActiveConfiguration();
  if (!face_config_) {
    DLOG(ERROR) << "Failed to create FaceConfiguration";
    return false;
  }

  // Transit from NOT_READY to IDLE state.
  state_ = IDLE;
  DLOG(INFO) << "State transit from NOT_READY to IDLE";
  return true;
}

void FaceTrackingObject::Destroy() {
  // Assure no race condition between current thread and face_tracking_thread_
  DCHECK(!face_tracking_thread_.IsRunning());

  if (face_config_) {
    face_config_->Release();
    face_config_ = NULL;
  }

  if (sense_manager_) {
    sense_manager_->Close();
    sense_manager_->Release();
    sense_manager_ = NULL;
  }

  if (session_) {
    session_->Release();
    session_ = NULL;
  }
  DLOG(INFO) << "Destroy, State transit from " << state_ << " to NOT_READY";
  state_ = NOT_READY;
}

bool FaceTrackingObject::CreateProcessedSampleImages() {
  DCHECK(!latest_color_image_);
  DCHECK(!latest_depth_image_);

  PXCCapture::Device::StreamProfileSet profiles = {};
  sense_manager_->QueryCaptureManager()->QueryDevice()
      ->QueryStreamProfileSet(&profiles);

  // color image.
  if (profiles.color.imageInfo.format) {
    // Only support color stream PIXEL_FORMAT_RGB32.
    if (profiles.color.imageInfo.format != PXCImage::PIXEL_FORMAT_RGB32) {
      DLOG(ERROR) << "Device color stream format is not RGB32: "
          << profiles.color.imageInfo.format;
      return false;
    }
    DLOG(INFO) << "color.imageInfo: width is " << profiles.color.imageInfo.width
        << ", height is " << profiles.color.imageInfo.height
        << ", format is "
        << PXCImage::PixelFormatToString(profiles.color.imageInfo.format);
    PXCImage::ImageInfo image_info = profiles.color.imageInfo;
    image_info.format = PXCImage::PIXEL_FORMAT_RGB32;
    latest_color_image_ = sense_manager_->QuerySession()
        ->CreateImage(&image_info);
  }
  // depth image.
  if (profiles.depth.imageInfo.format) {
    // Only support depth stream PIXEL_FORMAT_DEPTH.
    if (profiles.depth.imageInfo.format != PXCImage::PIXEL_FORMAT_DEPTH) {
      DLOG(ERROR) << "Device depth stream format is not DEPTH: "
          << profiles.depth.imageInfo.format;
      return false;
    }
    DLOG(INFO) << "depth.imageInfo: width is " << profiles.depth.imageInfo.width
        << ", height is " << profiles.depth.imageInfo.height
        << ", format is "
        << PXCImage::PixelFormatToString(profiles.depth.imageInfo.format);
    PXCImage::ImageInfo image_info = profiles.depth.imageInfo;
    image_info.format = PXCImage::PIXEL_FORMAT_DEPTH;
    latest_depth_image_ = sense_manager_->QuerySession()
        ->CreateImage(&image_info);
  }

  // At least should have color image!
  return latest_color_image_ != NULL;
}

void FaceTrackingObject::ReleasePipelineResources() {
  DCHECK_EQ(face_tracking_thread_.message_loop(), base::MessageLoop::current());

  binary_message_.reset();
  binary_message_size_ = 0;

  if (latest_color_image_) {
    latest_color_image_->Release();
    latest_color_image_ = NULL;
  }
  if (latest_depth_image_) {
    latest_depth_image_->Release();
    latest_depth_image_ = NULL;
  }
  if (face_output_) {
    face_output_->Release();
    face_output_ = NULL;
  }
  if (face_config_) {
    face_config_->Release();
    face_config_ = NULL;
  }
  sense_manager_->Close();

  DLOG(INFO) << "Release pipeline, State transit from "
      << state_ << " to NOT_READY";
  state_ = NOT_READY;
}

void FaceTrackingObject::StopFaceTrackingThread() {
  message_loop_->PostTask(
      FROM_HERE,
      base::Bind(&FaceTrackingObject::OnStopFaceTrackingThread,
                 base::Unretained(this)));
}

void FaceTrackingObject::OnStopFaceTrackingThread() {
  if (face_tracking_thread_.IsRunning()) {
    face_tracking_thread_.Stop();
  }
}

// binary message: call_id (int32),
// color format (int32), width (int32), height (int32), data (int8 buffer),
// depth format (int32), width (int32), height (int32), data (int16 buffer),
// number of faces (int32),
// detection data available (int32),
// landmark data available (int32),
// face data array:
//     array element: faceId (int32),
//                    rect x, y, w, h (int32), avgDepth (float32),
//                    landmark data: number of landmark points (int32),
//                                   landmark point data array:
//                                      array element:
//                                               type (int32),
//                                               image confidence (int32),
//                                               world confidence (int32),
//                                               world point x, y, z (float32),
//                                               image point x, y (float32),
size_t FaceTrackingObject::CalculateBinaryMessageSize() {
  const int image_header_size = 3 * sizeof(int);  // format, width, height
  PXCImage::ImageInfo color_info = latest_color_image_->QueryInfo();
  const int color_image_size = color_info.width * color_info.height * 4;

  int depth_image_size = 0;
  if (latest_depth_image_) {
    PXCImage::ImageInfo depth_info = latest_depth_image_->QueryInfo();
    depth_image_size = depth_info.width * depth_info.height * 2;
  }

  const int num_of_faces = face_output_->QueryNumberOfDetectedFaces();
  int one_face_size = 0;
  // size for faceId (int32)
  one_face_size += sizeof(int);

  if (face_config_->detection.isEnabled != 0) {
    one_face_size += (4 * sizeof(int) + sizeof(float));
  }
  if (face_config_->landmarks.isEnabled != 0) {
    int landmark_size = 0;
    // size for "number of landmark points"
    landmark_size += sizeof(int);
    // size for "one landmark point data"
    const int landmark_point_size = 3 * sizeof(int) + 5 * sizeof(float);
    landmark_size += face_config_->landmarks.numLandmarks * landmark_point_size;

    one_face_size += landmark_size;
  }

  const int message_size =
      // call_id
      sizeof(int)
      // color image
      + image_header_size + color_image_size
      // depth image
      + image_header_size + depth_image_size
      // faces
      + 3 * sizeof(int) + num_of_faces * one_face_size;
  return message_size;
}

}  // namespace face_tracking
}  // namespace realsense
