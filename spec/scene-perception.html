<!DOCTYPE html>
<html>
  <head>
    <title>Scene Perception</title>
    <meta charset='utf-8'>
    <script src='respec/respec-w3c-common.js'
            async class='remove'></script>
    <script class='remove'>
      var respecConfig = {
          // specification status (e.g. WD, LCWD, WG-NOTE, etc.). If in doubt use ED.
          specStatus:           "unofficial",

          additionalCopyrightHolders: "This document uses the BSD license, see the <a href='https://github.com/crosswalk-project/realsense-extensions-crosswalk/blob/master/LICENSE'>LICENSE</a> file.",

          shortName:            "scene-perception",
          // editors, add as many as you like
          // only "name" is required
          editors:  [
              {
                  name:       "Donna Wu"
              ,   company:    "Intel"
              ,   companyURL: "http://www.intel.com/"
              },
              {
                  name:       "Ningxin Hu"
              ,   company:    "Intel"
              ,   companyURL: "http://www.intel.com/"
              },
          ],
      };
    </script>
  </head>
  <body>
    <section id='abstract'>
      <p>
        This document describes support for creating a digital representation
        of the observed environment and estimating in real-time the camera pose
        by leveraging the 3D camera.
      </p>
    </section>

    <section id='sotd'>
      <p>
        This document was published by the <a href="https://crosswalk-project.org/">Crosswalk Project</a>
        as an API Draft.
        If you wish to make comments regarding this document, please send them to
        <a href="mailto:crosswalk-dev@lists.crosswalk-project.org">crosswalk-dev@lists.crosswalk-project.org</a>.
        All comments are welcome.
      </p>
    </section>

    <section>
      <h2>Introduction</h2>
      <p>
      </p>
    </section>
    <section>
      <h2>
        Interfaces
      </h2>
      <section>
        <h2>
          <code><a>ScenePerception</a></code>
        </h2>
        <p>
          The <code><a>ScenePerception</a></code> interface provides methods to
          track and scan scenes for augmented reality applications.
          The <code><a>ScenePerception</a></code> interface is exposed through
          <code>realsense</code> module.
        </p>
        <dl title='interface ScenePerception : EventTarget' class='idl'>
          <dt>
            Promise&lt;void&gt; init(optional InitialConfiguration config)
          </dt>
          <dd>
            Initialize the Scene Perception module with user-defined configuration.
            <dl class='parameters'>
              <dt>optional InitialConfiguration config</dt>
              <dd>
                The initial user defined configuration which will be passed to Scene Perception module.
              </dd>
            </dl>
          </dd>
          <dt>
            Promise&lt;void&gt; start()
          </dt>
          <dd>
            Start scene perception. This method should be called after the <code>init</code> get called and successfully returned, otherwise it will fail with error.
          </dd>
          <dt>
            Promise&lt;void&gt; stop()
          </dt>
          <dd>
            Stop scene perception. Calling this method will terminate the scene perception procedure. If scene perception has not been started, it will take no effect.
          </dd>
          <dt>
            Promise&lt;void&gt; reset()
          </dt>
          <dd>
            Reset scene perception module to its initial state.
          </dd>
          <dt>
            Promise&lt;void&gt; destroy()
          </dt>
          <dd>
            Destroy the scene perception object. After calling this method the scene perception object will no longer being valid, you need to call <code>init</code> to re-initialize it if you want to use again.
          </dd>
          <dt>
            Promise&lt;void&gt; enableReconstruction(boolean enable)
          </dt>
          <dd>
            Allows user to enable/disable integration of upcoming camera stream into 3D volume.
            If disabled the volume will not be updated. However scene perception will still keep tracking the camera.
            This is a control parameter which can be updated before passing every frame to the module.
            <dl class='parameters'>
              <dt>boolean enable</dt>
              <dd>
                Flag to enable/disable reconstruction.
              </dd>
            </dl>
          </dd>
          <dt>
            Promise&lt;void&gt; enableRelocalization(boolean enable)
          </dt>
          <dd>
            Allows user to enable/disable re-localization feature of scene perception's camera tracking.
            By default re-localization is enabled. This functionality is only available after <code><a>init</a></code> is called.
            <dl class='parameters'>
              <dt>boolean enable</dt>
              <dd>
                Flag to enable/disable re-localization.
              </dd>
            </dl>
          </dd>
          <dt>
            Promise&lt;boolean&gt; isReconstructionEnabled()
          </dt>
          <dd>
            Allows user to check whether integration of upcoming camera stream into 3D volume is enabled or disabled.
          </dd>
          <dt>
            Promise&lt;Sample&gt; getSample()
          </dt>
          <dd>
            Allows user to access the surface's capture sample that are within view from camera's current pose asynchronously.
          </dd>
          <dt>
            Promise&lt;Vertices&gt; getVertices()
          </dt>
          <dd>
            Allows user to access the surface's vertices that are within view from camera's current pose asynchronously.
          </dd>
          <dt>
            Promise&lt;Normals&gt; getNormals()
          </dt>
          <dd>
            Allows user to access normals of surface that are within view from the camera's current pose asynchronously.
          </dd>
          <dt>
            Promise&lt;Image&gt; queryVolumePreview(sequence&lt;float&gt; cameraPose)
          </dt>
          <dd>
            Allows user to access 2D projection image of reconstructed volume from a given camera pose by ray-casting.<br/>
            This function is optimized for real time performance. It is also useful for visualizing progress of the scene reconstruction.<br/>
            <dl class='parameters'>
              <dt>optional sequence&lt;float&gt; cameraPose</dt>
              <dd>
              This is a sequence of 12 float that stores the camera pose, which user wishes to set in row-major order. Camera pose is specified in a 3 by 4 matrix:<br/>
              <code>
              [R | T] = [Rotation Matrix | Translation Vector]<br/>
              where R = [ r11 r12 r13  ]<br/>
                        [ r21 r22 r23  ]<br/>
                        [ r31 r32 r33  ]<br/>
                        T = [ tx ty tz  ]<br/>
              </code>
              Camera pose sequense layout should be: <code>[r11 r12 r13 tx r21 r22 r23 ty r31 r32 r33 tz]</code><br/>
              Translation vector is in meters.
              </dd>
            </dl>
          </dd>
          <dt>
            Promise&lt;VolumePreviewData&gt; getVolumePreview(sequence&lt;float&gt; cameraPose)
          </dt>
          <dd>
            Returns the volume datails as a 2D projection image by reconstructing the volume with ray-casting, surface volume normals and surface volume faces for the specified camera pose.
            <br/>
            <p>
              This method returns a promise.
              The promise will be fulfilled with the VolumePreviewData instance if there are no errors.
              The promise will be rejected with the <code><a>DEPError</a></code> object if there is a failure.
            </p>
            <dl class='parameters'>
              <dt>optional sequence&lt;float&gt; cameraPose</dt>
              <dd>
              This is a sequence of 12 float that stores the camera pose, which user wishes to set in row-major order. Camera pose is specified in a 3 by 4 matrix:<br/>
              <code>
              [R | T] = [Rotation Matrix | Translation Vector]<br/>
              where R = [ r11 r12 r13  ]<br/>
                        [ r21 r22 r23  ]<br/>
                        [ r31 r32 r33  ]<br/>
                        T = [ tx ty tz  ]<br/>
              </code>
              Camera pose sequense layout should be: <code>[r11 r12 r13 tx r21 r22 r23 ty r31 r32 r33 tz]</code><br/>
              Translation vector is in meters.
              </dd>
            </dl>
          </dd>
          <dt>
            Promise&lt;VoxelResolution&gt; getVoxelResolution()
          </dt>
          <dd>
            To get voxel resolution used by the scene perception module.
          </dd>
          <dt>
            Promise&lt;float&gt; getVoxelSize()
          </dt>
          <dd>
            Allows user to get length of side of voxel cube in meters.
          </dd>
          <dt>
            Promise&lt;MeshingThresholds&gt; getMeshingThresholds()
          </dt>
          <dd>
            Allows user to get meshing thresholds used by scene perception.
          </dd>
          <dt>
            Promise&lt;MeshingResolution&gt; getMeshingResolution()
          </dt>
          <dd>
            Allows user to get meshing resolution.
          </dd>
          <dt>
            Promise&lt;MeshData&gt; getMeshData()
          </dt>
          <dd>
            Allows user to retrieve mesh data.
          </dd>
          <dt>
            Promise&lt;SurfaceVoxelsData&gt; getSurfaceVoxels(optional InterestRegion region)
          </dt>
          <dd>
            <p>
              The <code>getSurfaceVoxels</code> function exports the centers of the voxels intersected by the surface scanned.
              <br>
              The voxels size is set based on the resolution of the color images.
              <br>
              Optionally, you can specify the <code>region</code> of interested bounding box.
            </p>
            <p>
              The <code>getSurfaceVoxels</code> function returns promise.
              <br>
              The promise will be fulfilled with surface voxels in batches
              if there are no errors, the <code>dataPending</code> attribute in the result will be true when there are remaining surface voxels.
              <br>
              Please call the function again until the <code>dataPending</code> flag returns false.
              <br>
              The promise will be rejected if there is a failure.
            </p>
            <p>
              If <code>useColor</code> was set to <code>false</code> by calling <code>configureSurfaceVoxelsData</code> function before
              <code>getSurfaceVoxels</code> function, the <code>surfaceVoxelsColor</code> member of
              the returned result from <code>getSurfaceVoxels</code> function will be <code>null</code>.
            </p>
            <dl class='parameters'>
              <dt>optional InterestRegion region</dt>
                <dd>
                The optional region of interest by specifying the lower left and upper right of the region of interest bounding box.
                </dd>
              </dt>
            </dl>
          </dd>
          <dt>
            Promise&lt;Blob&gt; saveMesh(optional SaveMeshInfo info)
          </dt>
          <dd>
            <p>
              Save the mesh data of the volume to an ASCII file.
              It will return a blob with 'text/plain' type.
            </p>
            <dl class='parameters'>
              <dt>optional SaveMeshInfo info</dt>
              <dd>
                Information that needs to save mesh data.
              </dd>
            </dl>
          </dd>
          <dt>
            Promise&lt;void&gt; setMeshingResolution(MeshingResolution resolution)
          </dt>
          <dd>
            Allows user to set meshing resolution.
            <dl class='parameters'>
              <dt>MeshingResolution resolution</dt>
              <dd>
                Mesh resolution user wishes to set.
              </dd>
            </dl>
          </dd>
          <dt>
            Promise&lt;void&gt; setMeshingThresholds(MeshingThresholds thresholds)
          </dt>
          <dd>
            Is an optional function meant for expert users. It allows user to set meshing thresholds.<br/>
            The values set by this function will be used by succeeding calls to <code><a>getMeshData()</a></code>. Set the thresholds indicating the magnitude of changes occurring in any block that would be considered significant for re-meshing.
            <dl class='parameters'>
              <dt>MeshingThresholds thresholds</dt>
              <dd>
                Thresholds information that user wants to set.
              </dd>
            </dl>
          </dd>
          <dt>
            Promise&lt;void&gt; setCameraPose(sequence&lt;float&gt; cameraPose)
          </dt>
          <dd>
            Allows user to enforce the supplied pose as the camera pose. The module will track the camera from this pose when the next frame is passed. this function can be called any time after module finishes processing first frame or any time after module successfully processes the first frame post a call to reset scene perception.
            <dl class='parameters'>
              <dt>sequence&lt;float&gt; cameraPose</dt>
              <dd>
              This is a sequence of 12 float that stores the camera pose, which user wishes to set in row-major order. Camera pose is specified in a 3 by 4 matrix:<br/>
              <p><code>
              [R | T] = [Rotation Matrix | Translation Vector]<br/>
              where R = [ r11 r12 r13 ]<br/>
                        [ r21 r22 r23 ]<br/>
                        [ r31 r32 r33 ]<br/>
                    T = [ tx  ty  tz  ]<br/>
              </code></p>
              Camera pose sequense layout should be: <code>[r11 r12 r13 tx r21 r22 r23 ty r31 r32 r33 tz]</code><br/>
              Translation vector is in meters.
              </dd>
            </dl>
          </dd>
          <dt>
            Promise&lt;void&gt; setMeshingUpdateConfigs(MeshingUpdateConfigs config)
          </dt>
          <dd>
            Allows user to set meshing update configurations.
            <dl class='parameters'>
              <dt>MeshingUpdateConfigs config</dt>
              <dd>
                Argument to indicate which mesh data you wish to use.
              </dd>
            </dl>
          </dd>
          <dt>
            Promise&lt;void&gt; configureSurfaceVoxelsData(VoxelsDataConfig config)
          </dt>
          <dd>
            <p>
              This interface sets the configurations of <code>getSurfaceVoxels</code> function.
            </p>
            <dl class='parameters'>
              <dt>VoxelsDataConfig config</dt>
              <dd>
                Argument to indicate which configuration for surface's voxels data you wish to use.
              </dd>
            </dl>
          </dd>
          <dt>
            Promise&lt;void&gt; setMeshingRegion(InterestRegion region)
          </dt>
          <dd>
            The <code>setMeshingRegion</code> function sets the meshing region of interest for the <code>getMeshData</code> function.
            <br/>
            The region of interest is specified as a bounding box.
            <dl class='parameters'>
              <dt>InterestRegion region</dt>
                <dd>
                  The region of interest by specifying the lower left and upper right of the region of interest bounding box.
                </dd>
              </dt>
            </dl>
          </dd>
          <dt>
            Promise&lt;void&gt; clearMeshingRegion()
          </dt>
          <dd>
            The <code>clearMeshingRegion</code> function removes any previously set meshing region of insterest for the <code>getMeshData</code> function.
          </dd>
          <dt>
            attribute EventHandler onchecking
          </dt>
          <dd>
            <p>
              A property used to set the EventHandler (described in [[!HTML]])
              for the <a><code>CheckingEvent</code></a> that is dispatched
              to <code><a>ScenePerception</a></code> when a frame is checked.
            </p>
          </dd>
          <dt>
            attribute EventHandler onerror
          </dt>
          <dd>
            <p>
              A property used to set the EventHandler (described in [[!HTML]])
              for the <a><code>ErrorEvent</code></a> that is dispatched
              to <code><a>ScenePerception</a></code> when there is an error.
            </p>
          </dd>
          <dt>
            attribute EventHandler onmeshupdated
          </dt>
          <dd>
            <p>
              A property used to set the EventHandler (described in [[!HTML]])
              for the <a><code>Event</code></a> that is dispatched
              to <code><a>ScenePerception</a></code> when mesh is updated.
            </p>
          </dd>
          <dt>
            attribute EventHandler onsampleprocessed
          </dt>
          <dd>
            <p>
              A property used to set the EventHandler (described in [[!HTML]])
              for the <a><code>SampleProcessedEvent</code></a> that is dispatched
              to <code><a>ScenePerception</a></code> when mesh is updated.
            </p>
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>CheckingEvent</a></code>
        </h3>
        <dl class="idl" title="interface CheckingEvent : Event">
          <dt>
            readonly attribute float quality
          </dt>
          <dd>
            <p>
              a positive value between 0 and 1 to indicate how good is scene for starting, tracking or resetting scene perception.<br/>
              1.0 -> represents ideal scene for starting scene perception.<br/>
              0.0 -> represents unsuitable scene for starting scene perception.<br/>
            </p>
            <p>
              a negative value to indicate potential reasons of a tracking failure.<br/>
              -1.0 -> represents the scene lacks of structural/geometry information.<br/>
              -2.0 -> represents The scene lacks enough depth data (too far away from or close to the camera.)<br/>
            </p>
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>SampleProcessedEvent</a></code>
        </h3>
        <dl class="idl" title="interface SampleProcessedEvent : Event">
          <dt>
            readonly attribute float quality
          </dt>
          <dd>
            <p>
              a positive value between 0 and 1 to indicate how good is scene for starting, tracking or resetting scene perception.<br/>
              1.0 -> represents ideal scene for starting scene perception.<br/>
              0.0 -> represents unsuitable scene for starting scene perception.<br/>
            </p>
            <p>
              a negative value to indicate potential reasons of a tracking failure.<br/>
              -1.0 -> represents the scene lacks of structural/geometry information.<br/>
              -2.0 -> represents The scene lacks enough depth data (too far away from or close to the camera.)<br/>
            </p>
          </dd>
          <dt>
            readonly attribute TrackingAccuracy accuracy
          </dt>
          <dd>
          </dd>
          <dt>
            readonly attribute float[] cameraPose
          </dt>
          <dd>
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>SPError</a></code>
        </h2>
        <p>
          The error type from the reject callback of Promise.
        </p>
        <dl class="idl" title="interface SPError">
          <dt>
            readonly attribute ErrorCode error
          </dt>
          <dd>
            <p>
              The error code. See the <code><a>ErrorCode</a></code> enumerator for definition.
            </p>
          </dd>
          <dt>
            readonly attribute DOMString message
          </dt>
          <dd>
            <p>
              The descripton string for error.
            </p>
          </dd>
        </dl>
      </section>
    </section>
    <section>
      <h2>
        Dictionaries
      </h2>
      <section>
        <h2>
          <code><a>BlockMesh</a></code>
        </h2>
        <dl title='dictionary BlockMesh' class='idl'>
          <dt>
            unsigned long meshId
          </dt>
          <dd>
            Unique ID to identify each BlockMesh object.
          </dd>
          <dt>
            unsigned long vertexStartIndex
          </dt>
          <dd>
            Starting index of the vertex inside vertex buffer.
          </dd>
          <dt>
            unsigned long numVertices
          </dt>
          <dd>
            Total number of vertices inside this BlockMesh object.
          </dd>
          <dt>
            unsigned long faceStartIndex
          </dt>
          <dd>
            Starting index of the face list in a MeshFaces buffer.
          </dd>
          <dt>
            unsigned long numFaces
          </dt>
          <dd>
            Number of faces forming the mesh inside this BlockMesh object.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>CaptureSize</a></code>
        </h2>
        <dl title='dictionary CaptureSize' class='idl'>
          <dt>
            unsigned long width
          </dt>
          <dd>
            Width of the capture size in pixels.
          </dd>
          <dt>
            unsigned long height
          </dt>
          <dd>
            Height of the capture size in pixels.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>Image</a></code>
        </h2>
        <dl title='dictionary Image' class='idl'>
          <dt>
            PixelFormat format
          </dt>
          <dd>
            Describe the image sample pixel format.
          </dd>
          <dt>
            unsigned long width
          </dt>
          <dd>
            Width of the image in pixels.
          </dd>
          <dt>
            unsigned long height
          </dt>
          <dd>
            Height of the image in pixels.
          </dd>
          <dt>
            ArrayBuffer data
          </dt>
          <dd>
            Represents the image data.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>InitialConfiguration</a></code>
        </h2>
        <dl title='dictionary InitialConfiguration' class='idl'>
          <dt>
            boolean? useOpenCVCoordinateSystem;
          </dt>
          <dd>
          Indicates whether to use OpenCV coordinate system or not. Default value is <code>false</code>.
          </dd>
          <dt>
            VoxelResolution? voxelResolution;
          </dt>
          <dd>
            The initial voxel resolution. The voxelResolution is locked when <code><a>init</a></code> is called, afterwards it will remains same throughout the runtime of scene perception module. The default value of voxel resolution is LOW_RESOLUTION.
          </dd>
          <dt>
            sequence&lt;float&gt;? initialCameraPose;
          </dt>
          <dd>
            This is a sequence of 12 float that stores the camera pose, which user wishes to set in row-major order. Camera pose is specified in a 3 by 4 matrix:<br/>
<p><code>
            [R | T] = [Rotation Matrix | Translation Vector]<br/>
            where R = [ r11 r12 r13 ]<br/>
                      [ r21 r22 r23 ]<br/>
                      [ r31 r32 r33 ]<br/>
                  T = [ tx  ty  tz  ]<br/>
</code></p>
            Camera pose sequense layout should be: <code>[r11 r12 r13 tx r21 r22 r23 ty r31 r32 r33 tz]</code><br/>
            Translation vector is in meters.
          </dd>
          <dt>
            MeshingThresholds? meshingThresholds;
          </dt>
          <dd>
            The meshing threshold of scene perception.
          </dd>
          <dt>
            CaptureSize? colorCaptureSize;
          </dt>
          <dd>
            Indicates the color image capture size in pixel, default is 320 x 240.
          </dd>
          <dt>
            CaptureSize? depthCaptureSize;
          </dt>
          <dd>
            Indicates the depth image capture size in pixel, default value is 320 x 240.
          </dd>
          <dt>
            float? captureFramerate;
          </dt>
          <dd>
            Indicates the capture frame rate, default value is 60fps.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>InterestRegion</a></code>
        </h2>
        <dl title='dictionary InterestRegion' class='idl'>
          <dt>
            Point3D lowerLeftFrontPoint;
          </dt>
          <dd>
            The lower left point of the interest region.
          </dd>
          <dt>
            Point3D upperRightRearPoint;
          </dt>
          <dd>
            The upper right point of the interest region.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>MeshData</a></code>
        </h2>
        <dl title='dictionary MeshData' class='idl'>
          <dt>
            sequence&lt;BlockMesh&gt; blockMeshes
          </dt>
          <dd>
            Sequence of BlockMesh objects.
          </dd>
          <dt>
            unsigned long numberOfVertices;
          </dt>
          <dd>
            Represents number of vertices present in the MeshData buffer.
          </dd>
          <dt>
            Float32Array vertices;
          </dt>
          <dd>
          Represents an array of float points with length 4*<a>numberOfVertices</a>. Each vertex consists of 4 float points: (x, y, z) coordinates in meter unit + a confidence value. This confidence value is in the range [0, 1] indicating how confident scene perception is about the presence of the vertex.
          </dd>
          <dt>
            Uint8Array colors;
          </dt>
          <dd>
            Represents the array of colors with length 3*<a>numberOfVertices</a>. There are three color channels(RGB) per vertex.
          </dd>
          <dt>
            unsigned long numberOfFaces;
          </dt>
          <dd>
            Represent the number of faces in the buffer.
          </dd>
          <dt>
            Int32Array faces;
          </dt>
          <dd>
          Represents an array of faces forming the mesh (3 indices per triangle) valid range is from [0, 3*<a>numberOfFaces</a>].
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>MeshingThresholds</a></code>
        </h2>
        <dl title='dictionary MeshingThresholds' class='idl'>
          <dt>
            float max
          </dt>
          <dd>
            Represents the maximum threshold of meshing. If the maximum change in a block exceeds this value, then the block will be re-meshed. Setting this value to zero will retrieve all blocks.
          </dd>
          <dt>
            float avg
          </dt>
          <dd>
            Represents the average threshold of meshing. If the average change in a block exceeds this value, then the block will be re-mashed. Setting this value to zero will retrieve all blocks.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>MeshingUpdateInfo</a></code>
        </h2>
        <dl title='dictionary MeshingUpdateInfo' class='idl'>
          <dt>
            boolean countOfBlockMeshesRequired;
          </dt>
          <dd>
            If set, on successful call this function will set number of block meshes available for meshing.
          </dd>
          <dt>
            boolean blockMeshesRequired;
          </dt>
          <dd>
            Can only be set to true if <code>countOfBlockMeshesRequired</code> is set to true otherwise this value will be ignored. If set to true, on successfull call to this function it will update block meshes array.
          </dd>
          <dt>
            boolean countOfVerticesRequired;
          </dt>
          <dd>
            If set, on successful call to this function it will set number of vertices available for meshing.
          </dd>
          <dt>
            boolean verticesRequired;
          </dt>
          <dd>
            Can only be set if <code>countOfVerticesRequired</code> is set to true otherwise the value is ignored. If set, on successful call to this function it will update vertices array.
          </dd>
          <dt>
            boolean countOfFacesRequired;
          </dt>
          <dd>
            If set, on successful call to this function it will set number of faces available for meshing.
          </dd>
          <dt>
            boolean facesRequired;
          </dt>
          <dd>
          Can only be set if <code>countOfFacesRequired</code> is set to true otherwise the value is ignored. If set, on successful call to this function it will update faces array.
          </dd>
          <dt>
            boolean colorsRequired;
          </dt>
          <dd>
            If set and MeshData was created with color, on success function will fill in colors array.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>MeshingUpdateConfigs</a></code>
        </h2>
        <dl title='dictionary MeshingUpdateConfigs' class='idl'>
          <dt>
            boolean? fillHoles;
          </dt>
          <dd>
            Indicates whether to fill holes in mesh blocks or not. If set, it will fill missing details in each mesh block that are visible from scene perception's camera current pose and completely surrounded by closed surface(holes) by smooth linear interpolation of adjacent mesh data.
          </dd>
          <dt>
            MeshingUpdateInfo? updateInfo;
          </dt>
          <dd>
            Argument to indicate which mesh data you wish to use.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>Normals</a></code>
        </h2>
        <dd>
          Represents normal vector data.
        </dd>
        <dl title='dictionary Normals' class='idl'>
          <dt>
            unsigned long width
          </dt>
          <dd>
            Width of the normal vector.
          </dd>
          <dt>
            unsigned long height
          </dt>
          <dd>
            Height of the normal vector.
          </dd>
          <dt>
            Float32Array data
          </dt>
          <dd>
            Sequence of the normal vector. Each normal object consists of 3 float value (x, y, z).
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>Point3D</a></code>
        </h2>
        <dl title='dictionary Point3D' class='idl'>
          <dt>
            float x;
          </dt>
          <dd>
            The x coordinate of the point.
          </dd>
          <dt>
            float y;
          </dt>
          <dd>
            The y coordinate of the point.
          </dd>
          <dt>
            float z;
          </dt>
          <dd>
            The z coordinate of the point.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>Sample</a></code>
        </h2>
        <dd>
          The capture sample that contains multiple streams.
        </dd>
        <dl title='dictionary Sample' class='idl'>
          <dt>
            Image color
          </dt>
          <dd>
            Color image of the sample.
          </dd>
          <dt>
            Image depth
          </dt>
          <dd>
            Depth image of the sample.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>SaveMeshInfo</a></code>
        </h2>
        <dl title='dictionary SaveMeshInfo' class='idl'>
          <dt>
            boolean? fillMeshHoles;
          </dt>
          <dd>
            Flag which indicates whether to fill holes in saved mesh.
          </dd>
          <dt>
            boolean? saveMeshColor;
          </dt>
          <dd>
            Flag which indicates whether you wish to save mesh color.
          </dd>
          <dt>
            MeshingResolution? meshResolution;
          </dt>
          <dd>
            Indicates resolution for mesh to be saved.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>SurfaceVoxelsData</a></code>
        </h2>
        <dl title='dictionary SurfaceVoxelsData' class='idl'>
          <dt>
            boolean dataPending;
          </dt>
          <dd>
            Indicates whether there is remaining surface voxels data.
          </dd>
          <dt>
            Float32Buffer centerOfSurfaceVoxels
          </dt>
          <dd>
            The array of center of surface voxels.
          </dd>
          <dt>
            unsigned long numberOfSurfaceVoxels;
          </dt>
          <dd>
            The number of surface voxels.
          </dd>
          <dt>
            Uint8Array surfaceVoxelsColor;
          </dt>
          <dd>
            The array of color channels for voxels which contains the three RGB channels for each voxel.
            The data type of this array is Byte and the length is 3 * <code>numberOfSurfaceVoxels</code>.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>VolumePreviewData</a></code>
        </h2>
        <dd>
          Represents the volume preview data, including volume preview image dimensions, volume prview image data, vertices and normals.
        </dd>
        <dl title='dictionary VolumePreviewData' class='idl'>
          <dt>
            unsigned long width
          </dt>
          <dd>
            Width of the volume preview data.
          </dd>
          <dt>
            unsigned long height
          </dt>
          <dd>
            Height of the volume preview data.
          </dd>
          <dt>
            Uint32Array imageData
          </dt>
          <dd>
            Raw data of the projected volume image. Each pixel is a 4 byte RGBA data (a, r, g, b).
          </dd>
          <dt>
            Float32Array vertices
          </dt>
          <dd>
            Raw data of a sequence of vertices. Each vertex consists of 3 float values (x, y, z).
          </dd>
          <dt>
            Float32Array normals
          </dt>
          <dd>
            Raw data of a sequence of normals. Each normal consists of 3 float values (x, y, z).
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>Vertices</a></code>
        </h2>
        <dd>
          Represents vertices data.
        </dd>
        <dl title='dictionary Vertices' class='idl'>
          <dt>
            unsigned long width
          </dt>
          <dd>
            Width of the vertices buffer.
          </dd>
          <dt>
            unsigned long height
          </dt>
          <dd>
            Height of the vertices buffer.
          </dd>
          <dt>
            Float32Array data
          </dt>
          <dd>
            Raw data of a sequence of vertices. Each vertex consists of 3 float values (x, y, z).
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>VoxelsDataConfig</a></code>
        </h2>
        <dl title='dictionary VoxelsDataConfig' class='idl'>
          <dt>
            unsigned long voxelCount;
          </dt>
          <dd>
            The maximum number of voxels you can get by calling
            <code>getSurfaceVoxels</code> function.
          </dd>
          <dt>
            boolean useColor;
          </dt>
          <dd>
            Indicate if color should be returned per voxel when you call
            <code>getSurfaceVoxels</code> function.
          </dd>
        </dl>
      </section>
    </section>
    <section>
      <h2>
        Enumerators
      </h2>
      <section>
        <h2>
          <code><a>MeshingResolution</a></code>
        </h2>
        <dl id="enum-basic" class="idl" title="enum MeshingResolution">
          <dt>
            high
          </dt>
          <dd>
            <p>
              The high mesh resolution.
            </p>
          </dd>
          <dt>
            med
          </dt>
          <dd>
            <p>
              The median mesh resolution.
            </p>
          </dd>
          <dt>
            low
          </dt>
          <dd>
            <p>
              The low mesh resolution.
            </p>
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>TrackingAccuracy</a></code>
        </h2>
        <dl id="enum-basic" class="idl" title="enum TrackingAccuracy">
          <dt>
            high
          </dt>
          <dd>
            <p>
              The high tracking accuracy.
            </p>
          </dd>
          <dt>
            med
          </dt>
          <dd>
            <p>
              The median tracking accuracy.
            </p>
          </dd>
          <dt>
            low
          </dt>
          <dd>
            <p>
              The low tracking accuracy.
            </p>
          </dd>
          <dt>
            failed
          </dt>
          <dd>
            <p>
              The tracking is failed.
            </p>
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>VoxelResolution</a></code>
        </h2>
        <dl id="enum-basic" class="idl" title="enum VoxelResolution">
          <dt>
            high
          </dt>
          <dd>
            <p>
              The high voxel resolution. Use this resolution in a object-sized scenario (1/256m).
            </p>
          </dd>
          <dt>
            med
          </dt>
          <dd>
            <p>
              The median voxel resolution. Use this resolution in a table-top-sized scenario (2/256m).
            </p>
          </dd>
          <dt>
            low
          </dt>
          <dd>
            <p>
              The low voxel resolution. Use this resolution in a room-sized scenario (4/256m).
            </p>
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>PixelFormat</a></code>
        </h2>
        <dl id="enum-basic" class="idl" title="enum PixelFormat">
          <dt>
            RGBA32
          </dt>
          <dd>
            <p>
              The 32-bit RGBA32 color format. When <code>format</code> of
              an <code><a>Image</a></code> instance is set to <code>RGBA32</code>,
              the <code>data</code> of that image instance must follow the
              bytes layout of <a href="http://www.w3.org/TR/2dcontext/#canvas-pixel-arraybuffer">Canvas Pixel ArrayBuffer</a>
              defined in [[!CANVAS-2D]].
            </p>
          </dd>
          <dt>
            DEPTH
          </dt>
          <dd>
            <p>
              The depth map data in 16-bit unsigned integer.
              The values indicate the distance from an object to the camera's XY
              plane or the Cartesian depth.The value precision is in millimeters.
            </p>
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>ErrorCode</a></code> enum
        </h2>
        <dl id="enum-basic" class="idl" title="enum ErrorCode">
          <dt>
            feature_unsupported
          </dt>
          <dd>
            <p>
              The requested feature is not available or not implemented.
            </p>
          </dd>
          <dt>
            param_unsupported
          </dt>
          <dd>
            <p>
              There are invalid/unsupported parameters.
            </p>
          </dd>
          <dt>
            init_failed
          </dt>
          <dd>
            <p>
              The initialization failed.
            </p>
          </dd>
          <dt>
            exec_failed
          </dt>
          <dd>
            <p>
              The operation failed to execute.
            </p>
          </dd>
        </dl>
      </section>
    </section>
    <section class='informative'>
      <h2>
        Examples
      </h2>
      <section>
        <h3>
          Configure and Control Scene Perception(SP) module
        </h3>
        <pre class='example highlight'>
          // SP states and changing conditions.
          // -- IDLE
          // Before the pipeline is initialized.

          // -- INITIALIZED
          // Pipeline is initialized, SP module is paused.
          // Possible output in this state:
          //     checking event(depth quality)
          //
          //     getSample(raw color/depth image)

          // -- STARTED
          // SP module starts to work, receiving raw smaples and reconstructing the
          // volume space according to them.
          // Typically this state is triggerred when the depth quality
          // is acceptable.
          // SP module is on tracking, and on reconstructing if reconstruction
          // flag enabled.
          // Possible output in this state:
          //     sampleProcessed event(quality, tracking accuracy, camera pose)
          //     meshupdated event(no data)
          //
          //     getSample(processed sample including color/depth image)
          //     getMeshData
          //     get/query[XXX] interfaces to get configurations or data from SP module.

          // The changing diagram.
          // --sp.destory() from other states--> "IDEL" --sp.init()--> "INITIALIZED"
          // "INITIALIZED" --sp.start()--> "STARTED"
          // "STARTED" --sp.stop()--> "INITIALIZED"

          // This example will show the skeleton frame to init and control SP module.

          var sp = realsense.ScenePerception;

          var initButton = document.getElementById('init');
          var destroyButton = document.getElementById('destroy');
          var startButton = document.getElementById('startSP');
          var stopButton = document.getElementById('stopSP');

          // Set the initial state of buttons.
          resetButtonState(true);

          function resetButtonState(beforeStart) {
            initButton.disabled = !beforeStart;
            destroyButton.disabled = beforeStart;
            startButton.disabled = beforeStart;
            stopButton.disabled = true;
          }

          initButton.onclick = function(e) {
            // Please refer to InitialConfiguration for more info.
            var initConfig = {
              useOpenCVCoordinateSystem: true,
              colorCaptureSize: {'width':320, 'height':240},
              depthCaptureSize: {'width':320, 'height':240},
              captureFramerate: 60
            };
            sp.init(initConfig).then(function() {
              // Set the state of buttons.
              resetButtonState(false);

              // Other initialization work can be done here.
              console.log('init succeeds');
            }, function(e) {console.log(e);});
          };

          startButton.onclick = function(e) {
            sp.start().then(function() {
              startButton.disabled = true;
              stopButton.disabled = false;
              console.log('SP started successfully');
            }, function(e) {console.log(e);});
          };

          stopButton.onclick = function(e) {
            sp.stop().then(function() {
              console.log('SP stops working.');
              startButton.disabled = false;
              stopButton.disabled = true;
            }, function(e) {console.log(e);});
          };

          destroyButton.onclick = function(e) {
            sp.destroy().then(function() {
              console.log('stop succeeds');
              resetButtonState(true);
            }, function(e) {console.log(e);});
          };
        </pre>
      </section>
      <section>
        <h3>
          Handle events of SP module
        </h3>
        <pre class='example highlight'>
          var qualityElement = document.getElementById('quality');
          var accuracyElement = document.getElementById('accuracy');

          sp.onchecking = function(e) {
            var quality = e.data.quality;
            qualityElement.innerHTML = 'Quality: ' + quality.toFixed(2);
          };

          // Please refer to SampleProcessedEvent inferface for event data.
          sp.onsampleprocessed = function(e) {
            accuracyElement.innerHTML = 'Accuracy: ' + e.data.accuracy;
            qualityElement.innerHTML = 'Quality: ' + e.data.quality.toFixed(2);

            sp.getSample().then(function(sample) {
              // The sample object contains color image and depth image.
              // The image data structure, which could possibly look like this:
              // sample.color = {
              //                  width: imageWidth,
              //                  height: imageHeight,
              //                  data: Uint8Array
              //                };
              // sample.depth = {
              //                  width: imageWidth,
              //                  height: imageHeight,
              //                  data: Uint16Array
              //                };
              // Please refer to getSample interface for more details.
            }, function(e) {console.log(e);});

            sp.queryVolumePreview(e.data.cameraPose).then(function(volumePreview) {
              // The volume preview image data structure is similar with color and depth image in sample.
              // volumePreview = {
              //                   width: imageWidth,
              //                   height: imageHeight,
              //                   data: Uint8Array
              //                 };
              // Please refer to VolumePreviewData interface for detail data format.
            });
          };

          sp.onmeshupdated = function(e) {
            thisObj = this;
            sp.getMeshData().then(function(meshes) {
              // In the meshes, there are information about vertices, faces and color.
              // Meshes can be used to reconstruct the scanned scene by WebGL.
              // Please refer to MeshData inferface for more details.
            }, function(e) {console.log(e);});
          };

          sp.onerror = function(e) {console.log(e););
        </pre>
      </section>
    </section>
    <section class='appendix'>
      <h2>Acknowledgments</h2>
      <p>
      </p>
    </section>
  </body>
</html>
